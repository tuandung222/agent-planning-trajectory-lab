{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial: Planning Pattern Agent Interactive Lab (Microsoft Agent Framework + Claude)\n",
        "\n",
        "Audience:\n",
        "- Data Scientists and AI Researchers who prefer notebook-first exploration.\n",
        "\n",
        "Prerequisites:\n",
        "- Basic Python and async familiarity.\n",
        "- Conda env `vllm` available.\n",
        "- Valid `OPENAI_API_KEY` and `SERPER_API_KEY` (default provider).\n",
        "\n",
        "Learning goals:\n",
        "- Understand each Planning component (tools, planner, executor, synthesis).\n",
        "- Run an end-to-end inference from a topic to a markdown report.\n",
        "- Debug common failures (missing key, invalid key, API mismatch).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outline\n",
        "\n",
        "1. Environment and dependency setup\n",
        "2. API key checks and sanity diagnostics\n",
        "3. Interactive tool checks (`calculator`, `web_search`, `save_findings`)\n",
        "4. Workflow component inspection\n",
        "5. End-to-end inference run\n",
        "6. Pitfalls, extensions, and exercises\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: run once per fresh environment\n",
        "%pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if not (PROJECT_ROOT / 'main.py').exists():\n",
        "    raise RuntimeError('Run this notebook from examples/planning-claude-sdk-market-research')\n",
        "\n",
        "load_dotenv(PROJECT_ROOT / '.env')\n",
        "\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('UTC now:', datetime.utcnow().isoformat(timespec='seconds'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 - Check API keys and provider alignment\n",
        "\n",
        "This project defaults to **OpenAI** (`LLM_PROVIDER=openai`) via `OPENAI_API_KEY`.\n",
        "If you switch to Anthropic, set `LLM_PROVIDER=anthropic` and use `ANTHROPIC_API_KEY`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _key_status(name: str) -> str:\n",
        "    v = os.getenv(name, '').strip()\n",
        "    if not v:\n",
        "        return 'MISSING'\n",
        "    return 'PRESENT'\n",
        "\n",
        "provider = os.getenv('LLM_PROVIDER', 'openai').strip().lower()\n",
        "print('LLM_PROVIDER     :', provider)\n",
        "print('OPENAI_API_KEY   :', _key_status('OPENAI_API_KEY'))\n",
        "print('ANTHROPIC_API_KEY:', _key_status('ANTHROPIC_API_KEY'))\n",
        "print('SERPER_API_KEY   :', _key_status('SERPER_API_KEY'))\n",
        "print('OPENAI_MODEL     :', os.getenv('OPENAI_MODEL', 'gpt-4.1-mini'))\n",
        "print('ANTHROPIC_MODEL  :', os.getenv('ANTHROPIC_MODEL', 'claude-opus-4-6'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 - Interact with tools directly\n",
        "\n",
        "Before full workflow inference, test each component in isolation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from tools import calculator, web_search, save_findings\n",
        "\n",
        "async def tool_smoke_test():\n",
        "    print('calculator:', await calculator('((47.1 / 5.43) ** (1/6) - 1) * 100'))\n",
        "    save_msg = await save_findings('tool_smoke.md', '# Tool Smoke Test\\n\\nSuccess')\n",
        "    print('save_findings:', save_msg)\n",
        "\n",
        "    if os.getenv('SERPER_API_KEY'):\n",
        "        search_result = await web_search('AI agent market size 2026')\n",
        "        print('web_search sample (first 500 chars):')\n",
        "        print(search_result[:500])\n",
        "    else:\n",
        "        print('web_search skipped: SERPER_API_KEY missing')\n",
        "\n",
        "await tool_smoke_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 - Build and inspect planning workflow\n",
        "\n",
        "This verifies planner -> executor -> synthesis wiring before inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from planning_workflow import PlanningMarketResearchWorkflow\n",
        "\n",
        "topic = 'AI agent market size 2024-2026'\n",
        "\n",
        "if not os.getenv('LLM provider API key'):\n",
        "    print('Cannot instantiate workflow: LLM provider API key missing')\n",
        "    workflow = None\n",
        "else:\n",
        "    workflow = PlanningMarketResearchWorkflow(topic=topic)\n",
        "    print('Workflow object created for topic:', topic)\n",
        "    print('Internal workflow type:', type(workflow.workflow).__name__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 - End-to-end inference\n",
        "\n",
        "This runs the full planning pipeline and writes a markdown report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_FILE = PROJECT_ROOT / 'outputs' / 'planning_notebook_report.md'\n",
        "\n",
        "async def run_inference(topic: str):\n",
        "    provider = os.getenv('LLM_PROVIDER', 'openai').strip().lower()\n",
        "    if provider == 'openai' and not os.getenv('OPENAI_API_KEY'):\n",
        "        raise RuntimeError('OPENAI_API_KEY is required when LLM_PROVIDER=openai')\n",
        "    if provider == 'anthropic' and not os.getenv('ANTHROPIC_API_KEY'):\n",
        "        raise RuntimeError('ANTHROPIC_API_KEY is required when LLM_PROVIDER=anthropic')\n",
        "\n",
        "    wf = PlanningMarketResearchWorkflow(topic=topic)\n",
        "    report = await wf.execute()\n",
        "\n",
        "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
        "    OUTPUT_FILE.write_text(report, encoding='utf-8')\n",
        "    return report\n",
        "\n",
        "try:\n",
        "    final_report = await run_inference(topic)\n",
        "    print('Inference succeeded. Report saved to:', OUTPUT_FILE)\n",
        "    print('--- Report preview (first 1000 chars) ---')\n",
        "    print(final_report[:1000])\n",
        "except Exception as e:\n",
        "    print('Inference failed:', e)\n",
        "    print('Hint: verify provider and API keys in .env')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common pitfalls\n",
        "\n",
        "- **Wrong key type**: OpenAI key (`sk-proj-...`) used as `ANTHROPIC_API_KEY` causes `401 invalid x-api-key`.\n",
        "- **Missing SERPER key**: planning runs but web search tool returns errors or empty data.\n",
        "- **Package drift**: `agent-framework` pre-release APIs can change; pin versions when moving to production.\n",
        "\n",
        "## Optional extensions\n",
        "\n",
        "- Add JSON schema validation for planner output.\n",
        "- Add token/cost logging per phase (planning, execution, synthesis).\n",
        "- Add fallback from Planning to ReAct when steps fail repeatedly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "1. Change the topic to your domain (finance, healthcare, supply chain).\n",
        "2. Compare output quality with and without calculator steps.\n",
        "3. Record one failure mode and your mitigation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise scaffold\n",
        "my_topic = 'YOUR_TOPIC_HERE'\n",
        "\n",
        "# Uncomment to run:\n",
        "# final_report = await run_inference(my_topic)\n",
        "# print(final_report[:1200])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
