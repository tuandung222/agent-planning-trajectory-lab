{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 09. Trajectory to Training Dataset\n",
        "\n",
        "Convert trajectory logs into training-ready samples.\n"
      ],
      "id": "74472972"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import statistics\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    for candidate in [start, *start.parents]:\n",
        "        if (candidate / 'README.md').exists() and (candidate / 'main_langgraph.py').exists():\n",
        "            return candidate\n",
        "    return start\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd().resolve())\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print('PROJECT_ROOT =', PROJECT_ROOT)\n"
      ],
      "id": "4313410d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "trace_candidates = sorted((PROJECT_ROOT / 'test_outputs').glob('**/run_*.jsonl'))\n",
        "\n",
        "if trace_candidates:\n",
        "    jsonl_path = trace_candidates[-1]\n",
        "    rows = [json.loads(line) for line in jsonl_path.read_text().splitlines() if line.strip()]\n",
        "    print('Using trace:', jsonl_path)\n",
        "else:\n",
        "    rows = [\n",
        "        {'run_id': 'mock', 'idx': 1, 'event_type': 'tool_call', 'payload': {'tool': 'web_search', 'kwargs': {'query': 'AI planning'}}},\n",
        "        {'run_id': 'mock', 'idx': 2, 'event_type': 'tool_result', 'payload': {'tool': 'web_search', 'ok': True, 'latency_ms': 100, 'result_preview': 'sample'}},\n",
        "    ]\n",
        "    print('Using synthetic rows')\n"
      ],
      "id": "898ab970"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "tool_calls = [r for r in rows if r.get('event_type') == 'tool_call']\n",
        "tool_results = [r for r in rows if r.get('event_type') == 'tool_result']\n",
        "paired = min(len(tool_calls), len(tool_results))\n",
        "\n",
        "sft_samples = []\n",
        "for i in range(paired):\n",
        "    c = tool_calls[i]\n",
        "    r = tool_results[i]\n",
        "    sft_samples.append({\n",
        "        'prompt': f\"Tool={c['payload'].get('tool')} kwargs={c['payload'].get('kwargs')}\",\n",
        "        'completion': f\"ok={r['payload'].get('ok')} preview={r['payload'].get('result_preview')}\",\n",
        "    })\n",
        "\n",
        "print('sft_samples=', len(sft_samples))\n",
        "assert len(sft_samples) >= 1\n"
      ],
      "id": "9a8ed430"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "out_dir = PROJECT_ROOT / 'test_outputs' / 'series_datasets'\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_path = out_dir / 'sft_samples.jsonl'\n",
        "\n",
        "with out_path.open('w', encoding='utf-8') as f:\n",
        "    for item in sft_samples:\n",
        "        f.write(json.dumps(item, ensure_ascii=True) + '\\n')\n",
        "\n",
        "print('saved:', out_path)\n"
      ],
      "id": "401f447c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}